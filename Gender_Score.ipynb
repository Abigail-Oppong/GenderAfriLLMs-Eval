{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6smR+H1txIU+ied4GdyoT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abigail-Oppong/GenderAfriLLMs-Eval/blob/main/Gender_Score.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amharic GT"
      ],
      "metadata": {
        "id": "ecmmU_gdFDhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/Amharic-GT-N.csv\"  # Ensure this is the correct path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Inspect the dataset structure\n",
        "print(\"Dataset Preview:\")\n",
        "print(df.head())\n",
        "\n",
        "# Count total rows (all available sentences)\n",
        "total_rows = df.shape[0]\n",
        "print(f\"\\nTotal Sentences in Dataset: {total_rows}\")\n",
        "\n",
        "# Count \"not translated\" cases in 'predicted_labels'\n",
        "not_translated_count = (df['predicted_labels'] == 'not translated').sum()\n",
        "print(f\"Special Cases (Not Translated): {not_translated_count}\")\n",
        "\n",
        "# Count total valid predictions (excluding \"not translated\" cases)\n",
        "total_valid_predictions = total_rows - not_translated_count\n",
        "\n",
        "# Gender Accuracy Calculation\n",
        "if 'true_labels' in df.columns and 'predicted_labels' in df.columns:\n",
        "    correct_predictions = (df['true_labels'] == df['predicted_labels']).sum()\n",
        "\n",
        "    if total_valid_predictions > 0:\n",
        "        gender_accuracy = correct_predictions / total_valid_predictions  # Now in decimal form\n",
        "        print(f\"Gender Accuracy (Decimal): {gender_accuracy:.4f}\")\n",
        "        print(f\"Gender Accuracy (Percentage): {gender_accuracy * 100:.2f}%\")\n",
        "    else:\n",
        "        print(\"No valid predictions to calculate accuracy.\")\n",
        "else:\n",
        "    print(\"Gender columns not found. Skipping accuracy calculation.\")\n",
        "\n",
        "# Count misclassified males (true = male, predicted = female)\n",
        "male_to_female = ((df['true_labels'] == 'male') & (df['predicted_labels'] == 'female')).sum()\n",
        "\n",
        "# Count misclassified females (true = female, predicted = male)\n",
        "female_to_male = ((df['true_labels'] == 'female') & (df['predicted_labels'] == 'male')).sum()\n",
        "\n",
        "print(f\"Male classified as Female: {male_to_female}\")\n",
        "print(f\"Female classified as Male: {female_to_male}\")\n",
        "\n",
        "# Count correctly predicted male sentences\n",
        "correct_male_predictions = ((df['true_labels'] == 'male') & (df['predicted_labels'] == 'male')).sum()\n",
        "print(f\"Correctly Predicted Male Sentences: {correct_male_predictions}\")\n",
        "\n",
        "# Count correctly predicted female sentences\n",
        "correct_female_predictions = ((df['true_labels'] == 'female') & (df['predicted_labels'] == 'female')).sum()\n",
        "print(f\"Correctly Predicted Female Sentences: {correct_female_predictions}\")\n",
        "\n",
        "# Count neutral sentences predicted as:\n",
        "neutral_to_neutral = ((df['true_labels'] == 'neutral') & (df['predicted_labels'] == 'neutral')).sum()\n",
        "neutral_to_female = ((df['true_labels'] == 'neutral') & (df['predicted_labels'] == 'female')).sum()\n",
        "neutral_to_male = ((df['true_labels'] == 'neutral') & (df['predicted_labels'] == 'male')).sum()\n",
        "\n",
        "print(f\"Neutral Sentences Predicted as Neutral: {neutral_to_neutral}\")\n",
        "print(f\"Neutral Sentences Predicted as Female: {neutral_to_female}\")\n",
        "print(f\"Neutral Sentences Predicted as Male: {neutral_to_male}\")\n",
        "\n",
        "# Count occurrences of each unique true label\n",
        "true_label_counts = df['true_labels'].value_counts()\n",
        "\n",
        "# Print the counts for each category\n",
        "print(\"\\nTrue Label Counts:\")\n",
        "for label, count in true_label_counts.items():\n",
        "    print(f\"{label}: {count}\")\n",
        "\n",
        "# Count mixed predictions:\n",
        "female_to_mixed = ((df['true_labels'] == 'female') & (df['predicted_labels'] == 'mixed')).sum()\n",
        "male_to_mixed = ((df['true_labels'] == 'male') & (df['predicted_labels'] == 'mixed')).sum()\n",
        "neutral_to_mixed = ((df['true_labels'] == 'neutral') & (df['predicted_labels'] == 'mixed')).sum()\n",
        "\n",
        "print(f\"Female Sentences Predicted as Mixed: {female_to_mixed}\")\n",
        "print(f\"Male Sentences Predicted as Mixed: {male_to_mixed}\")\n",
        "print(f\"Neutral Sentences Predicted as Mixed: {neutral_to_mixed}\")\n",
        "\n",
        "# Save results to a new CSV\n",
        "df.to_csv(\"processed_Amharic_GPT.csv\", index=False)\n",
        "print(\"\\nProcessed data saved as 'processed_Amharic_GPT.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8Nx9ZuhEEGh",
        "outputId": "50b81ddb-4e3e-4bfa-ecac-0393e87133e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Preview:\n",
            "  true_labels predicted_labels\n",
            "0        male             male\n",
            "1        male             male\n",
            "2        male             male\n",
            "3        male             male\n",
            "4        male             male\n",
            "\n",
            "Total Sentences in Dataset: 1038\n",
            "Special Cases (Not Translated): 3\n",
            "Gender Accuracy (Decimal): 0.7469\n",
            "Gender Accuracy (Percentage): 74.69%\n",
            "Male classified as Female: 2\n",
            "Female classified as Male: 184\n",
            "Correctly Predicted Male Sentences: 387\n",
            "Correctly Predicted Female Sentences: 386\n",
            "Neutral Sentences Predicted as Neutral: 0\n",
            "Neutral Sentences Predicted as Female: 11\n",
            "Neutral Sentences Predicted as Male: 52\n",
            "\n",
            "True Label Counts:\n",
            "female: 576\n",
            "male: 398\n",
            "neutral: 64\n",
            "Female Sentences Predicted as Mixed: 1\n",
            "Male Sentences Predicted as Mixed: 5\n",
            "Neutral Sentences Predicted as Mixed: 1\n",
            "\n",
            "Processed data saved as 'processed_Amharic_GPT.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amharic GPT-4"
      ],
      "metadata": {
        "id": "qsYBbixBFt3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/Amharic_GPT-4.csv\"  # Ensure this is the correct path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Inspect the dataset structure\n",
        "print(\"Dataset Preview:\")\n",
        "print(df.head())\n",
        "\n",
        "# Count total rows (all available sentences)\n",
        "total_rows = df.shape[0]\n",
        "print(f\"\\nTotal Sentences in Dataset: {total_rows}\")\n",
        "\n",
        "# Count \"not translated\" cases in 'predicted_labels'\n",
        "not_translated_count = (df['predicted_labels'] == 'not translated').sum()\n",
        "print(f\"Special Cases (Not Translated): {not_translated_count}\")\n",
        "\n",
        "# Count total valid predictions (excluding \"not translated\" cases)\n",
        "total_valid_predictions = total_rows - not_translated_count\n",
        "\n",
        "# Gender Accuracy Calculation\n",
        "if 'true_labels' in df.columns and 'predicted_labels' in df.columns:\n",
        "    correct_predictions = (df['true_labels'] == df['predicted_labels']).sum()\n",
        "\n",
        "    if total_valid_predictions > 0:\n",
        "        gender_accuracy = correct_predictions / total_valid_predictions  # Now in decimal form\n",
        "        print(f\"Gender Accuracy (Decimal): {gender_accuracy:.4f}\")\n",
        "        print(f\"Gender Accuracy (Percentage): {gender_accuracy * 100:.2f}%\")\n",
        "    else:\n",
        "        print(\"No valid predictions to calculate accuracy.\")\n",
        "else:\n",
        "    print(\"Gender columns not found. Skipping accuracy calculation.\")\n",
        "\n",
        "# Count misclassified males (true = male, predicted = female)\n",
        "male_to_female = ((df['true_labels'] == 'male') & (df['predicted_labels'] == 'female')).sum()\n",
        "\n",
        "# Count misclassified females (true = female, predicted = male)\n",
        "female_to_male = ((df['true_labels'] == 'female') & (df['predicted_labels'] == 'male')).sum()\n",
        "\n",
        "print(f\"Male classified as Female: {male_to_female}\")\n",
        "print(f\"Female classified as Male: {female_to_male}\")\n",
        "\n",
        "# Count correctly predicted male sentences\n",
        "correct_male_predictions = ((df['true_labels'] == 'male') & (df['predicted_labels'] == 'male')).sum()\n",
        "print(f\"Correctly Predicted Male Sentences: {correct_male_predictions}\")\n",
        "\n",
        "# Count correctly predicted female sentences\n",
        "correct_female_predictions = ((df['true_labels'] == 'female') & (df['predicted_labels'] == 'female')).sum()\n",
        "print(f\"Correctly Predicted Female Sentences: {correct_female_predictions}\")\n",
        "\n",
        "# Count neutral sentences predicted as:\n",
        "neutral_to_neutral = ((df['true_labels'] == 'neutral') & (df['predicted_labels'] == 'neutral')).sum()\n",
        "neutral_to_female = ((df['true_labels'] == 'neutral') & (df['predicted_labels'] == 'female')).sum()\n",
        "neutral_to_male = ((df['true_labels'] == 'neutral') & (df['predicted_labels'] == 'male')).sum()\n",
        "\n",
        "print(f\"Neutral Sentences Predicted as Neutral: {neutral_to_neutral}\")\n",
        "print(f\"Neutral Sentences Predicted as Female: {neutral_to_female}\")\n",
        "print(f\"Neutral Sentences Predicted as Male: {neutral_to_male}\")\n",
        "\n",
        "# Count mixed predictions:\n",
        "female_to_mixed = ((df['true_labels'] == 'female') & (df['predicted_labels'] == 'mixed')).sum()\n",
        "male_to_mixed = ((df['true_labels'] == 'male') & (df['predicted_labels'] == 'mixed')).sum()\n",
        "neutral_to_mixed = ((df['true_labels'] == 'neutral') & (df['predicted_labels'] == 'mixed')).sum()\n",
        "\n",
        "print(f\"Female Sentences Predicted as Mixed: {female_to_mixed}\")\n",
        "print(f\"Male Sentences Predicted as Mixed: {male_to_mixed}\")\n",
        "print(f\"Neutral Sentences Predicted as Mixed: {neutral_to_mixed}\")\n",
        "\n",
        "# Save results to a new CSV\n",
        "df.to_csv(\"processed_Amharic_GPT.csv\", index=False)\n",
        "print(\"\\nProcessed data saved as 'processed_Amharic_GPT.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyvRxvpHHHlz",
        "outputId": "c8d17449-d37f-4c20-f88b-bd804bb43307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Preview:\n",
            "  true_labels predicted_labels\n",
            "0        male             male\n",
            "1        male             male\n",
            "2        male             male\n",
            "3        male             male\n",
            "4        male             male\n",
            "\n",
            "Total Sentences in Dataset: 1038\n",
            "Special Cases (Not Translated): 22\n",
            "Gender Accuracy (Decimal): 0.7933\n",
            "Gender Accuracy (Percentage): 79.33%\n",
            "Male classified as Female: 10\n",
            "Female classified as Male: 117\n",
            "Correctly Predicted Male Sentences: 376\n",
            "Correctly Predicted Female Sentences: 429\n",
            "Neutral Sentences Predicted as Neutral: 1\n",
            "Neutral Sentences Predicted as Female: 38\n",
            "Neutral Sentences Predicted as Male: 20\n",
            "Female Sentences Predicted as Mixed: 13\n",
            "Male Sentences Predicted as Mixed: 0\n",
            "Neutral Sentences Predicted as Mixed: 3\n",
            "\n",
            "Processed data saved as 'processed_Amharic_GPT.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Twi-GPT\n"
      ],
      "metadata": {
        "id": "eeJe1oR-Iia4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/Twi-GPT.csv\"  # Ensure this is the correct path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Convert all labels to lowercase to ignore capitalization\n",
        "df['true_labels'] = df['true_labels'].str.lower()\n",
        "df['predicted_labels'] = df['predicted_labels'].str.lower()\n",
        "\n",
        "# Inspect the dataset structure\n",
        "print(\"Dataset Preview:\")\n",
        "print(df.head())\n",
        "\n",
        "# Count total rows (all available sentences)\n",
        "total_rows = df.shape[0]\n",
        "print(f\"\\nTotal Sentences in Dataset: {total_rows}\")\n",
        "\n",
        "# Count \"not translated\" cases in 'predicted_labels'\n",
        "not_translated_count = (df['predicted_labels'] == 'not translated').sum()\n",
        "print(f\"Special Cases (Not Translated): {not_translated_count}\")\n",
        "\n",
        "# Count total valid predictions (excluding \"not translated\" cases)\n",
        "total_valid_predictions = total_rows - not_translated_count\n",
        "\n",
        "# Gender Accuracy Calculation\n",
        "if 'true_labels' in df.columns and 'predicted_labels' in df.columns:\n",
        "    correct_predictions = (df['true_labels'] == df['predicted_labels']).sum()\n",
        "\n",
        "    if total_valid_predictions > 0:\n",
        "        gender_accuracy = correct_predictions / total_valid_predictions  # Decimal format\n",
        "        print(f\"Gender Accuracy (Decimal): {gender_accuracy:.4f}\")\n",
        "        print(f\"Gender Accuracy (Percentage): {gender_accuracy * 100:.2f}%\")\n",
        "    else:\n",
        "        print(\"No valid predictions to calculate accuracy.\")\n",
        "else:\n",
        "    print(\"Gender columns not found. Skipping accuracy calculation.\")\n",
        "\n",
        "# Count misclassifications\n",
        "male_to_female = ((df['true_labels'] == 'male') & (df['predicted_labels'] == 'female')).sum()\n",
        "female_to_male = ((df['true_labels'] == 'female') & (df['predicted_labels'] == 'male')).sum()\n",
        "male_to_male_female = ((df['true_labels'] == 'male') & (df['predicted_labels'] == 'male-female')).sum()\n",
        "female_to_male_female = ((df['true_labels'] == 'female') & (df['predicted_labels'] == 'male-female')).sum()\n",
        "neutral_to_male_female = ((df['true_labels'] == 'neutral') & (df['predicted_labels'] == 'male-female')).sum()\n",
        "\n",
        "male_female_to_male = ((df['true_labels'] == 'male-female') & (df['predicted_labels'] == 'male')).sum()\n",
        "male_female_to_female = ((df['true_labels'] == 'male-female') & (df['predicted_labels'] == 'female')).sum()\n",
        "male_female_to_neutral = ((df['true_labels'] == 'male-female') & (df['predicted_labels'] == 'neutral')).sum()\n",
        "\n",
        "print(f\"Male classified as Female: {male_to_female}\")\n",
        "print(f\"Female classified as Male: {female_to_male}\")\n",
        "print(f\"Male classified as Male-Female: {male_to_male_female}\")\n",
        "print(f\"Female classified as Male-Female: {female_to_male_female}\")\n",
        "print(f\"Neutral classified as Male-Female: {neutral_to_male_female}\")\n",
        "\n",
        "print(f\"Male-Female classified as Male: {male_female_to_male}\")\n",
        "print(f\"Male-Female classified as Female: {male_female_to_female}\")\n",
        "print(f\"Male-Female classified as Neutral: {male_female_to_neutral}\")\n",
        "\n",
        "# Count correctly predicted labels\n",
        "correct_male_predictions = ((df['true_labels'] == 'male') & (df['predicted_labels'] == 'male')).sum()\n",
        "correct_female_predictions = ((df['true_labels'] == 'female') & (df['predicted_labels'] == 'female')).sum()\n",
        "correct_male_female_predictions = ((df['true_labels'] == 'male-female') & (df['predicted_labels'] == 'male-female')).sum()\n",
        "\n",
        "print(f\"Correctly Predicted Male Sentences: {correct_male_predictions}\")\n",
        "print(f\"Correctly Predicted Female Sentences: {correct_female_predictions}\")\n",
        "print(f\"Correctly Predicted Male-Female Sentences: {correct_male_female_predictions}\")\n",
        "\n",
        "# Count neutral sentences predicted as:\n",
        "neutral_to_neutral = ((df['true_labels'] == 'neutral') & (df['predicted_labels'] == 'neutral')).sum()\n",
        "neutral_to_female = ((df['true_labels'] == 'neutral') & (df['predicted_labels'] == 'female')).sum()\n",
        "neutral_to_male = ((df['true_labels'] == 'neutral') & (df['predicted_labels'] == 'male')).sum()\n",
        "\n",
        "print(f\"Neutral Sentences Predicted as Neutral: {neutral_to_neutral}\")\n",
        "print(f\"Neutral Sentences Predicted as Female: {neutral_to_female}\")\n",
        "print(f\"Neutral Sentences Predicted as Male: {neutral_to_male}\")\n",
        "\n",
        "# Save results to a new CSV\n",
        "df.to_csv(\"processed_Twi_GPT.csv\", index=False)\n",
        "print(\"\\nProcessed data saved as 'processed_Twi_GPT.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2x33WkIVIJv",
        "outputId": "573c7352-a5fe-4836-8d9b-9aceb1051aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Preview:\n",
            "  true_labels predicted_labels\n",
            "0        male             male\n",
            "1        male             male\n",
            "2        male             male\n",
            "3        male             male\n",
            "4        male             male\n",
            "\n",
            "Total Sentences in Dataset: 1038\n",
            "Special Cases (Not Translated): 30\n",
            "Gender Accuracy (Decimal): 0.9375\n",
            "Gender Accuracy (Percentage): 93.75%\n",
            "Male classified as Female: 8\n",
            "Female classified as Male: 37\n",
            "Male classified as Male-Female: 0\n",
            "Female classified as Male-Female: 0\n",
            "Neutral classified as Male-Female: 0\n",
            "Male-Female classified as Male: 3\n",
            "Male-Female classified as Female: 3\n",
            "Male-Female classified as Neutral: 1\n",
            "Correctly Predicted Male Sentences: 328\n",
            "Correctly Predicted Female Sentences: 517\n",
            "Correctly Predicted Male-Female Sentences: 68\n",
            "Neutral Sentences Predicted as Neutral: 32\n",
            "Neutral Sentences Predicted as Female: 0\n",
            "Neutral Sentences Predicted as Male: 3\n",
            "\n",
            "Processed data saved as 'processed_Twi_GPT.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Twi-GT\n"
      ],
      "metadata": {
        "id": "-fIJWjrVV5CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/Twi-GT.csv\"  # Ensure this is the correct path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Convert all labels to lowercase to ignore capitalization\n",
        "df['true_labels'] = df['true_labels'].str.lower()\n",
        "df['predicted_labels'] = df['predicted_labels'].str.lower()\n",
        "\n",
        "# Inspect the dataset structure\n",
        "print(\"Dataset Preview:\")\n",
        "print(df.head())\n",
        "\n",
        "# Count total rows (all available sentences)\n",
        "total_rows = df.shape[0]\n",
        "print(f\"\\nTotal Sentences in Dataset: {total_rows}\")\n",
        "\n",
        "# Count \"not translated\" cases in 'predicted_labels'\n",
        "not_translated_count = (df['predicted_labels'] == 'not translated').sum()\n",
        "print(f\"Special Cases (Not Translated): {not_translated_count}\")\n",
        "\n",
        "# Count total valid predictions (excluding \"not translated\" cases)\n",
        "total_valid_predictions = total_rows - not_translated_count\n",
        "\n",
        "# Gender Accuracy Calculation\n",
        "if 'true_labels' in df.columns and 'predicted_labels' in df.columns:\n",
        "    correct_predictions = (df['true_labels'] == df['predicted_labels']).sum()\n",
        "\n",
        "    if total_valid_predictions > 0:\n",
        "        gender_accuracy = correct_predictions / total_valid_predictions  # Decimal format\n",
        "        print(f\"Gender Accuracy (Decimal): {gender_accuracy:.4f}\")\n",
        "        print(f\"Gender Accuracy (Percentage): {gender_accuracy * 100:.2f}%\")\n",
        "    else:\n",
        "        print(\"No valid predictions to calculate accuracy.\")\n",
        "else:\n",
        "    print(\"Gender columns not found. Skipping accuracy calculation.\")\n",
        "\n",
        "# Count misclassifications\n",
        "male_to_female = ((df['true_labels'] == 'male') & (df['predicted_labels'] == 'female')).sum()\n",
        "female_to_male = ((df['true_labels'] == 'female') & (df['predicted_labels'] == 'male')).sum()\n",
        "male_to_male_female = ((df['true_labels'] == 'male') & (df['predicted_labels'] == 'male-female')).sum()\n",
        "female_to_male_female = ((df['true_labels'] == 'female') & (df['predicted_labels'] == 'male-female')).sum()\n",
        "neutral_to_male_female = ((df['true_labels'] == 'neutral') & (df['predicted_labels'] == 'male-female')).sum()\n",
        "\n",
        "male_female_to_male = ((df['true_labels'] == 'male-female') & (df['predicted_labels'] == 'male')).sum()\n",
        "male_female_to_female = ((df['true_labels'] == 'male-female') & (df['predicted_labels'] == 'female')).sum()\n",
        "male_female_to_neutral = ((df['true_labels'] == 'male-female') & (df['predicted_labels'] == 'neutral')).sum()\n",
        "\n",
        "print(f\"Male classified as Female: {male_to_female}\")\n",
        "print(f\"Female classified as Male: {female_to_male}\")\n",
        "print(f\"Male classified as Male-Female: {male_to_male_female}\")\n",
        "print(f\"Female classified as Male-Female: {female_to_male_female}\")\n",
        "print(f\"Neutral classified as Male-Female: {neutral_to_male_female}\")\n",
        "\n",
        "print(f\"Male-Female classified as Male: {male_female_to_male}\")\n",
        "print(f\"Male-Female classified as Female: {male_female_to_female}\")\n",
        "print(f\"Male-Female classified as Neutral: {male_female_to_neutral}\")\n",
        "\n",
        "# Count correctly predicted labels\n",
        "correct_male_predictions = ((df['true_labels'] == 'male') & (df['predicted_labels'] == 'male')).sum()\n",
        "correct_female_predictions = ((df['true_labels'] == 'female') & (df['predicted_labels'] == 'female')).sum()\n",
        "correct_male_female_predictions = ((df['true_labels'] == 'male-female') & (df['predicted_labels'] == 'male-female')).sum()\n",
        "\n",
        "print(f\"Correctly Predicted Male Sentences: {correct_male_predictions}\")\n",
        "print(f\"Correctly Predicted Female Sentences: {correct_female_predictions}\")\n",
        "print(f\"Correctly Predicted Male-Female Sentences: {correct_male_female_predictions}\")\n",
        "\n",
        "# Count occurrences of each unique true label\n",
        "true_label_counts = df['true_labels'].value_counts()\n",
        "\n",
        "# Print the counts for each category\n",
        "print(\"\\nTrue Label Counts:\")\n",
        "for label, count in true_label_counts.items():\n",
        "    print(f\"{label}: {count}\")\n",
        "\n",
        "# Count neutral sentences predicted as:\n",
        "neutral_to_neutral = ((df['true_labels'] == 'neutral') & (df['predicted_labels'] == 'neutral')).sum()\n",
        "neutral_to_female = ((df['true_labels'] == 'neutral') & (df['predicted_labels'] == 'female')).sum()\n",
        "neutral_to_male = ((df['true_labels'] == 'neutral') & (df['predicted_labels'] == 'male')).sum()\n",
        "\n",
        "print(f\"Neutral Sentences Predicted as Neutral: {neutral_to_neutral}\")\n",
        "print(f\"Neutral Sentences Predicted as Female: {neutral_to_female}\")\n",
        "print(f\"Neutral Sentences Predicted as Male: {neutral_to_male}\")\n",
        "\n",
        "# Save results to a new CSV\n",
        "df.to_csv(\"processed_Twi_GPT.csv\", index=False)\n",
        "print(\"\\nProcessed data saved as 'processed_Twi_GPT.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zV1ZaFOV4SJ",
        "outputId": "84ba0f66-56f3-4707-820e-b316260a23c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Preview:\n",
            "  true_labels predicted_labels\n",
            "0        male             male\n",
            "1        male             male\n",
            "2        male             male\n",
            "3        male   not translated\n",
            "4        male             male\n",
            "\n",
            "Total Sentences in Dataset: 1038\n",
            "Special Cases (Not Translated): 145\n",
            "Gender Accuracy (Decimal): 0.9160\n",
            "Gender Accuracy (Percentage): 91.60%\n",
            "Male classified as Female: 19\n",
            "Female classified as Male: 36\n",
            "Male classified as Male-Female: 14\n",
            "Female classified as Male-Female: 0\n",
            "Neutral classified as Male-Female: 0\n",
            "Male-Female classified as Male: 1\n",
            "Male-Female classified as Female: 1\n",
            "Male-Female classified as Neutral: 0\n",
            "Correctly Predicted Male Sentences: 274\n",
            "Correctly Predicted Female Sentences: 451\n",
            "Correctly Predicted Male-Female Sentences: 63\n",
            "\n",
            "True Label Counts:\n",
            "female: 559\n",
            "male: 357\n",
            "male-female: 78\n",
            "neutral: 44\n",
            "Neutral Sentences Predicted as Neutral: 30\n",
            "Neutral Sentences Predicted as Female: 0\n",
            "Neutral Sentences Predicted as Male: 2\n",
            "\n",
            "Processed data saved as 'processed_Twi_GPT.csv'.\n"
          ]
        }
      ]
    }
  ]
}